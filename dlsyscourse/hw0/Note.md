## hw0

主要就是复习一下机器学习/深度学习模型训练的过程  

1. 选择模型, 线性分类器或带一个relu的双层神经网络, 选择损失函数softmax_loss
2. 实现模型的前向传播, 即按模型结构计算`y=wx+b`, `y=w2(relu(w1x+b1))+b2`
3. 实现反向传播, 就是在损失函数做梯度下降, 但是对损失函数求w的偏导, 在大型神经网络中w来自不同的层/计算图上不同的点, 所以要沿着计算图反向走一遍更新w的值


矩阵乘法求导:
```
Y=matmul(X, W)
X.shape=(m, k)
W.shape=(k, n)

dX = matmul(dY, W.T)
dW = matmul(X.T, dY)

```